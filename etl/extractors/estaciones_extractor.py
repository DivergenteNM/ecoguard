"""
Extractor de Estaciones de IDEAM y Terceros
Dataset ID: 57sv-p2fu
Fuente: datos.gov.co (Socrata SODA API)
"""

import requests
import pandas as pd
from typing import Optional, List, Dict
import os
from dotenv import load_dotenv
import logging

# Cargar variables de entorno
load_dotenv()

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class EstacionesIDEAMExtractor:
    """
    Extractor para el dataset de Estaciones de IDEAM y Terceros.
    
    Funcionalidades:
    - Extracci√≥n de estaciones por departamento
    - Filtrado por tipo de estaci√≥n
    - Filtrado por estado (activa/inactiva)
    - Validaci√≥n de coordenadas geogr√°ficas
    - Exportaci√≥n a CSV y GeoJSON
    """
    
    def __init__(self, app_token: Optional[str] = None):
        """
        Inicializa el extractor.
        
        Args:
            app_token: Token de aplicaci√≥n de Socrata (opcional)
        """
        # Configuraci√≥n
        self.base_url = os.getenv('SOCRATA_BASE_URL', 'https://www.datos.gov.co/resource')
        self.dataset_id = os.getenv('ESTACIONES_DATASET_ID', '57sv-p2fu')
        self.endpoint = f"{self.base_url}/{self.dataset_id}.json"
        
        # Token de autenticaci√≥n
        self.app_token = app_token or os.getenv('SOCRATA_APP_TOKEN')
        
        # Headers
        self.headers = {}
        if self.app_token:
            self.headers['X-App-Token'] = self.app_token
            logger.info("‚úÖ Usando App Token para autenticaci√≥n")
        else:
            logger.warning("‚ö†Ô∏è  No se encontr√≥ App Token. L√≠mite: 100 requests/hora")
        
        # Estad√≠sticas
        self.total_requests = 0
        self.total_records = 0
    
    def _make_request(self, params: Dict) -> Optional[List[Dict]]:
        """
        Realiza una petici√≥n a la API con manejo de errores.
        
        Args:
            params: Par√°metros de la consulta
            
        Returns:
            Lista de registros o None si hay error
        """
        try:
            self.total_requests += 1
            
            response = requests.get(
                self.endpoint,
                params=params,
                headers=self.headers,
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                self.total_records += len(data)
                return data
            else:
                logger.error(f"‚ùå Error API: Status {response.status_code}")
                logger.error(f"Response: {response.text}")
                return None
                
        except requests.exceptions.Timeout:
            logger.error("‚ùå Timeout en la petici√≥n")
            return None
        except requests.exceptions.RequestException as e:
            logger.error(f"‚ùå Error de conexi√≥n: {e}")
            return None
        except Exception as e:
            logger.error(f"‚ùå Error inesperado: {e}")
            return None
    
    def extract_by_departamento(
        self, 
        departamento: str = 'NARI√ëO',
        limit: int = 10000
    ) -> pd.DataFrame:
        """
        Extrae estaciones de un departamento espec√≠fico.
        
        Args:
            departamento: Nombre del departamento
            limit: N√∫mero m√°ximo de registros
            
        Returns:
            DataFrame con las estaciones
        """
        logger.info(f"üîÑ Extrayendo estaciones de {departamento}...")
        
        params = {
            '$where': f"departamento='{departamento.upper()}'",
            '$limit': limit,
            '$order': 'municipio'
        }
        
        data = self._make_request(params)
        
        if data:
            df = pd.DataFrame(data)
            logger.info(f"‚úÖ Extra√≠das {len(df)} estaciones de {departamento}")
            return df
        else:
            return pd.DataFrame()
    
    def extract_active_stations(
        self, 
        departamento: str = 'NARI√ëO'
    ) -> pd.DataFrame:
        """
        Extrae solo estaciones activas de un departamento.
        
        Args:
            departamento: Nombre del departamento
            
        Returns:
            DataFrame con estaciones activas
        """
        logger.info(f"üîÑ Extrayendo estaciones activas de {departamento}...")
        
        # Primero extraer todas
        df_all = self.extract_by_departamento(departamento)
        
        if df_all.empty:
            return pd.DataFrame()
        
        # Filtrar por estado si existe la columna
        if 'estado' in df_all.columns:
            df_active = df_all[df_all['estado'].str.upper() == 'ACTIVA']
            logger.info(f"‚úÖ {len(df_active)} estaciones activas encontradas")
            return df_active
        else:
            logger.warning("‚ö†Ô∏è  Columna 'estado' no encontrada, retornando todas")
            return df_all
    
    def extract_by_municipio(
        self, 
        municipio: str,
        departamento: str = 'NARI√ëO'
    ) -> pd.DataFrame:
        """
        Extrae estaciones de un municipio espec√≠fico.
        
        Args:
            municipio: Nombre del municipio
            departamento: Nombre del departamento
            
        Returns:
            DataFrame con las estaciones del municipio
        """
        logger.info(f"üîÑ Extrayendo estaciones de {municipio}, {departamento}...")
        
        params = {
            '$where': f"departamento='{departamento.upper()}' AND municipio='{municipio.upper()}'",
            '$order': 'nombreestacion'
        }
        
        data = self._make_request(params)
        
        if data:
            df = pd.DataFrame(data)
            logger.info(f"‚úÖ Extra√≠das {len(df)} estaciones de {municipio}")
            return df
        else:
            return pd.DataFrame()
    
    def extract_by_tipo(
        self, 
        tipo_estacion: str,
        departamento: str = 'NARI√ëO'
    ) -> pd.DataFrame:
        """
        Extrae estaciones por tipo.
        
        Args:
            tipo_estacion: Tipo de estaci√≥n (ej: 'METEOROLOGICA', 'HIDROMETRICA')
            departamento: Nombre del departamento
            
        Returns:
            DataFrame con estaciones del tipo especificado
        """
        logger.info(f"üîÑ Extrayendo estaciones tipo {tipo_estacion}...")
        
        # Extraer todas del departamento
        df_all = self.extract_by_departamento(departamento)
        
        if df_all.empty:
            return pd.DataFrame()
        
        # Filtrar por tipo si existe la columna
        if 'tipo' in df_all.columns:
            df_tipo = df_all[df_all['tipo'].str.upper().str.contains(tipo_estacion.upper(), na=False)]
            logger.info(f"‚úÖ {len(df_tipo)} estaciones tipo {tipo_estacion}")
            return df_tipo
        else:
            logger.warning("‚ö†Ô∏è  Columna 'tipo' no encontrada")
            return pd.DataFrame()
    
    def validate_coordinates(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Valida y limpia coordenadas geogr√°ficas.
        
        Args:
            df: DataFrame con estaciones
            
        Returns:
            DataFrame con coordenadas validadas
        """
        logger.info("üîÑ Validando coordenadas...")
        
        if df.empty:
            return df
        
        # Convertir a num√©rico
        if 'latitud' in df.columns:
            df['latitud'] = pd.to_numeric(df['latitud'], errors='coerce')
        if 'longitud' in df.columns:
            df['longitud'] = pd.to_numeric(df['longitud'], errors='coerce')
        
        # Contar registros antes
        total_antes = len(df)
        
        # Filtrar coordenadas v√°lidas para Nari√±o
        # Latitud: 0.5¬∞ a 2.5¬∞ N
        # Longitud: -79.5¬∞ a -76.5¬∞ W
        df_valid = df[
            (df['latitud'] >= 0.5) & (df['latitud'] <= 2.5) &
            (df['longitud'] >= -79.5) & (df['longitud'] <= -76.5)
        ].copy()
        
        total_despues = len(df_valid)
        removidos = total_antes - total_despues
        
        if removidos > 0:
            logger.warning(f"‚ö†Ô∏è  {removidos} registros removidos por coordenadas inv√°lidas")
        
        logger.info(f"‚úÖ {total_despues} estaciones con coordenadas v√°lidas")
        
        return df_valid
    
    def get_estadisticas_por_municipio(
        self, 
        departamento: str = 'NARI√ëO'
    ) -> pd.DataFrame:
        """
        Obtiene estad√≠sticas de estaciones por municipio.
        
        Args:
            departamento: Nombre del departamento
            
        Returns:
            DataFrame con conteo por municipio
        """
        logger.info("üîÑ Obteniendo estad√≠sticas por municipio...")
        
        df = self.extract_by_departamento(departamento)
        
        if df.empty:
            return pd.DataFrame()
        
        # Agrupar por municipio
        stats = df.groupby('municipio').size().reset_index(name='total_estaciones')
        stats = stats.sort_values('total_estaciones', ascending=False)
        
        logger.info(f"‚úÖ Estad√≠sticas de {len(stats)} municipios")
        
        return stats
    
    def save_to_csv(self, df: pd.DataFrame, filename: str) -> str:
        """
        Guarda DataFrame a CSV.
        
        Args:
            df: DataFrame a guardar
            filename: Nombre del archivo (sin extensi√≥n)
            
        Returns:
            Ruta del archivo guardado
        """
        output_dir = os.path.join(os.path.dirname(__file__), '..', '..', 'datasets', 'raw')
        os.makedirs(output_dir, exist_ok=True)
        
        filepath = os.path.join(output_dir, f"{filename}.csv")
        df.to_csv(filepath, index=False, encoding='utf-8')
        
        logger.info(f"üíæ Guardado en: {filepath}")
        return filepath
    
    def save_to_geojson(self, df: pd.DataFrame, filename: str) -> str:
        """
        Guarda DataFrame a GeoJSON (requiere geopandas).
        
        Args:
            df: DataFrame con columnas latitud y longitud
            filename: Nombre del archivo (sin extensi√≥n)
            
        Returns:
            Ruta del archivo guardado
        """
        try:
            import geopandas as gpd
            from shapely.geometry import Point
            
            # Validar coordenadas
            df_valid = self.validate_coordinates(df)
            
            if df_valid.empty:
                logger.error("‚ùå No hay datos con coordenadas v√°lidas")
                return ""
            
            # Crear geometr√≠a
            geometry = [Point(xy) for xy in zip(df_valid['longitud'], df_valid['latitud'])]
            gdf = gpd.GeoDataFrame(df_valid, geometry=geometry, crs='EPSG:4326')
            
            # Guardar
            output_dir = os.path.join(os.path.dirname(__file__), '..', '..', 'datasets', 'processed')
            os.makedirs(output_dir, exist_ok=True)
            
            filepath = os.path.join(output_dir, f"{filename}.geojson")
            gdf.to_file(filepath, driver='GeoJSON')
            
            logger.info(f"üíæ GeoJSON guardado en: {filepath}")
            return filepath
            
        except ImportError:
            logger.warning("‚ö†Ô∏è  geopandas no instalado. Instalar con: pip install geopandas")
            return ""
        except Exception as e:
            logger.error(f"‚ùå Error al guardar GeoJSON: {e}")
            return ""
    
    def get_stats(self) -> Dict:
        """
        Obtiene estad√≠sticas del extractor.
        
        Returns:
            Diccionario con estad√≠sticas
        """
        return {
            'total_requests': self.total_requests,
            'total_records': self.total_records,
            'using_token': bool(self.app_token)
        }


# Ejemplo de uso
if __name__ == "__main__":
    # Crear extractor
    extractor = EstacionesIDEAMExtractor()
    
    # Extraer estaciones de Nari√±o
    df_narino = extractor.extract_by_departamento('NARI√ëO')
    
    if not df_narino.empty:
        print("\n" + "="*60)
        print("üìä RESUMEN DE DATOS EXTRA√çDOS")
        print("="*60)
        print(f"\nTotal de estaciones: {len(df_narino)}")
        print(f"\nColumnas disponibles:")
        for col in df_narino.columns:
            print(f"  - {col}")
        
        # Validar coordenadas
        df_valid = extractor.validate_coordinates(df_narino)
        print(f"\nüìç Estaciones con coordenadas v√°lidas: {len(df_valid)}")
        
        # Estad√≠sticas por municipio
        stats = extractor.get_estadisticas_por_municipio()
        print(f"\nüìä Top 10 municipios con m√°s estaciones:")
        print(stats.head(10).to_string(index=False))
        
        # Guardar a CSV
        extractor.save_to_csv(df_valid, 'estaciones_ideam_narino')
        
        # Intentar guardar GeoJSON
        extractor.save_to_geojson(df_valid, 'estaciones_ideam_narino')
        
        # Estad√≠sticas del extractor
        stats_extractor = extractor.get_stats()
        print(f"\nüìà Estad√≠sticas del extractor:")
        print(f"  - Requests realizados: {stats_extractor['total_requests']}")
        print(f"  - Registros obtenidos: {stats_extractor['total_records']}")
        print(f"  - Usando token: {'‚úÖ S√≠' if stats_extractor['using_token'] else '‚ùå No'}")
